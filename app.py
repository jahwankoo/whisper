import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import av
import whisper
import numpy as np
import tempfile
import os
from scipy.io.wavfile import write

st.set_page_config(page_title="Whisper AI Voice Recorder", layout="centered")
st.title("ğŸ¤ Whisper AI Voice Recorder & Transcriber")

# Whisper ëª¨ë¸ ë¡œë“œ
@st.cache_resource
def load_model():
    return whisper.load_model("base")

model = load_model()

# Audio Processor ì •ì˜
class AudioProcessor(AudioProcessorBase):
    def __init__(self):
        self.frames = []

    def recv_audio(self, frame: av.AudioFrame) -> av.AudioFrame:
        # ì˜¤ë””ì˜¤ í”„ë ˆì„ ëˆ„ì 
        audio = frame.to_ndarray()
        self.frames.append(audio)
        return frame

# WebRTC ë…¹ìŒ ìœ„ì ¯
webrtc_ctx = webrtc_streamer(
    key="whisper-audio",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=1024,
    media_stream_constraints={"audio": True, "video": False},
    async_processing=True,
)

# Whisper ë³€í™˜ ë²„íŠ¼
if webrtc_ctx and webrtc_ctx.audio_receiver:
    if st.button("ğŸ§ Stop & Transcribe"):
        with st.spinner("Processing..."):
            # ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì§‘
            audio_frames = []
            while True:
                try:
                    frame = webrtc_ctx.audio_receiver.get_frame(timeout=1)
                except:
                    break
                audio_frames.append(frame.to_ndarray())

            if audio_frames:
                # ì˜¤ë””ì˜¤ í•©ì¹˜ê¸°
                audio = np.concatenate(audio_frames, axis=1).T.astype(np.float32)
                fs = 48000

                # ì„ì‹œ íŒŒì¼ ì €ì¥
                tmp_dir = tempfile.mkdtemp()
                wav_path = os.path.join(tmp_dir, "recorded.wav")
                write(wav_path, fs, audio)
                st.success(f"Saved: {wav_path}")
                st.audio(wav_path)

                # Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
                result = model.transcribe(wav_path, language="ko")
                st.subheader("ğŸ“ Transcribed Text:")
                st.write(result["text"])

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                with open(wav_path, "rb") as f:
                    st.download_button("â¬‡ï¸ Download Recording", f, file_name="recorded.wav")
            else:
                st.warning("No audio data captured.")
